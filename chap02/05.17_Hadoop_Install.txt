설치 방법 사이트(https://phoenixnap.com/kb/install-hadoop-ubuntu)

Hadoop 설치 (terminal)
1. sudo apt update (현재 리눅스의 애플리케이션의 설치정보를 최신버전으로 업데이트한다.)

2. sudo apt install openjdk-8-jdk -y (현재 하둡은 자바 8이 넘어가면 하둡이 안돌아갈 수 있다.)

3. java -version; javac -version (자바가 설치 되어있는지 확인)
# OpenSSH 필요 (클러스트 안에서 컴퓨터끼리 통신이 가능하다.)

4. sudo apt install openssh-server openssh-client  -y (OpenSSH 설치)
# hdoop ALL=(ALL:ALL) ALL (sudo명령어 사용할 수 있는 유저 추가)
# SSH 클러스트에 속해 있는 컴퓨터들은 아이디와 패스워드가 동일해야한다.

5. ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa (동일한 키젠을 가지게 한다.)

6. cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys (클러스트 내에서 사용되는 암호를 .ssh/id_rsa.pub 밑에 작성)

7. chmod 0600 ~/.ssh/authorized_keys (클러스트가 추가될때마다 소유자만 읽고쓰게 하기위한 권한주기) 

8. ssh localhost (클러스트끼리 통신하기위한 통신규약 SSH를 실행하는 것.) yes입력

9. wget https://archive.apache.org/dist/hadoop/common/hadoop-3.2.2/hadoop-3.2.2.tar.gz (하둡설치 링크)
# linux의 압축 확장명 gz

10. tar -xvzf hadoop-3.2.2.tar.gz (하둡 압축해제 명령어, 파일명이 같아야 한다.)
# mv 사용하여 디렉토리 이름 변경 (mv hadoop-3.2.2 hadoop)

11. sudo nano .bashrc  (설정파일 편집)

12. (집에서는 hduser = jshoon으로 변경)
(.bashrc를 열었다면, 환경변수 설정.맨밑에 작성)
#Hadoop Related Options
export HADOOP_HOME=/home/hduser/hadoop
export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"

13. source .bashrc(실행적용)

14. which java(자바 설치경로 확인)

15. ls -al /usr/bin/java -> /etc/alternatives/java/ -> (java 상태확인)

16. nano $HADOOP_HOME/etc/hadoop/hadoop-env.sh (설정할 파일(hadoop-env.sh) 열기)
# 안될시 hadoop경로까지간 후 hadoop-env.sh가 있는지 확인 후 열기

17. export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 (자바홈 설정 / 맨밑에 설정할 내용 등록 후 엔터)

18. source $HADOOP_HOME/etc/hadoop/hadoop-env.sh(실행적용)
# echo명령어 print와 같다. echo $JAVA_HOME 출력해본다.

19. nano $HADOOP_HOME/etc/hadoop/core-site.xml (설정할 파일(core-site.xml) 열기)

20. (집에서는 hduser = jshoon으로 변경)
(configuration안에 적용하기)
<configuration>
<property>
  <name>hadoop.tmp.dir</name>
  <value>/home/hduser/tmpdata</value> 
</property>
<property>
  <name>fs.default.name</name>
  <value>hdfs://127.0.0.1:9000</value>
</property>
</configuration>

21. mkdir tmpdata (hadoop.tmp.dir에서 사용할때 tmpdata를 사용하기 때문에 tmpdata디렉토리를 만들어야한다.)

22. nano $HADOOP_HOME/etc/hadoop/hdfs-site.xml (설정할 파일(hdfs-site.xml) 열기)

23. (집에서는 hduser = jshoon으로 변경)
(configuration안에 적용하기)
<configuration>
<property>
  <name>dfs.data.dir</name>
  <value>/home/hduser/dfsdata/namenode</value>
</property>
<property>
  <name>dfs.data.dir</name>
  <value>/home/hduser/dfsdata/datanode</value>
</property>
<property>
  <name>dfs.replication</name>
  <value>1</value>
</property>
</configuration>

24. mkdir -p dfsdata/namenode (dfs.data.dir에서 데이터 저장할때 dfsdata, dfsdata안에 namenode,datanode를 사용하기 때문에 디렉토리를 만들어야한다.)

25. mkdir datanode (cd dfsdata 후 만들기)

26. nano $HADOOP_HOME/etc/hadoop/mapred-site.xml (설정할 파일(mapred-site.xml) 열기)

27. 
(configuration안에 적용하기)
<configuration> 
<property> 
  <name>mapreduce.framework.name</name> 
  <value>yarn</value> 
</property> 
</configuration>

28. nano $HADOOP_HOME/etc/hadoop/yarn-site.xml (설정할 파일(yarn-site.xml) 열기)

29. 
(configuration안에 적용하기)
<configuration>
<property>
  <name>yarn.nodemanager.aux-services</name>
  <value>mapreduce_shuffle</value>
</property>
<property>
  <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
  <value>org.apache.hadoop.mapred.ShuffleHandler</value>
</property>
<property>
  <name>yarn.resourcemanager.hostname</name>
  <value>127.0.0.1</value>
</property>
<property>
  <name>yarn.acl.enable</name>
  <value>0</value>
</property>
<property>
  <name>yarn.nodemanager.env-whitelist</name>   
  <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PERPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
</property>
</configuration>

30. hdfs namenode -format (명령어 딱 한번만 해야한다. 지금까지 설정한것을 문제가 있는지도 확인해줌)
# 확장자가 sh = 쉘스크립 실행프로그램.
# dfs = 분산파일시스템 

31. start-dfs.sh (자바버추얼머신 실행.)

32. jps (실행 후 자바프로그램이 몇개 실행되는지 확인. 3개 실행해야함.)

33. start-yarn.sh(매니저 두개 실행해야함.)

34. jps (실행 후 프로그램이 몇개 실행되는지 확인. 5개 실행해야함.)

35. start-all.sh (프로그램 한번에 실행 시키기.)

36. stop-all.sh(자바버추얼머신 종료.)

37. Namenode 현 상황 확인 (파이어폭스 실행 주소창에 http://localhost:9870)
38. Datanode 현 상황 확인 (파이어폭스 실행 주소창에 http://localhost:9864)
39. 리소스매니저 현 상황 확인 (파이어폭스 실행 주소창에 http://localhost:8088)
40. sudo shutdown now (터미널 종료)
